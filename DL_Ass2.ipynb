{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd28b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary libraries to import\n",
    "import tensorflow as tf \n",
    "# tensorflow is a open source free library used for the neural network\n",
    "from tensorflow import keras# user free neural network library used for neural network.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for visualisation purpose\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9582c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading and Preparing the Data\n",
    "MNIST stands for Modified National Institute of Standard and technology dataset.It basicaally contains 70000 handwritten images\n",
    "Each Image is of 28*28 pixels.\n",
    "ie. about 784 features Each feature represents only 1 pixel intensity ie. from 0 to 255.\n",
    "This dataset further divided into the 60000 trained images and 10000 testing images.'''\n",
    "mnist=tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9639c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(x_train[0]) # is basically used for to see how first image looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images by scaling the pixels intensities to the range 0 and 1.\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6434a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The ReLu function is one of the most popular activation function.\n",
    "It stands for Rectified Linear Unit .Mathematically this functionis defined as y=max(0,x).\n",
    "The ReLu function returns 0 if the input is negative and linear if the input is positive.\n",
    "The Softmax function is another Activation Function.It changes input values that reach from 0 and 1.'''\n",
    "model=keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "# sequential allows us to build the model layer by layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee91147",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea244228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e70136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca688efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "test_loss,test_acc=model.evaluate(x_test,y_test)\n",
    "print(\"Loss=%.3f\" %test_loss)\n",
    "print(\"Accuracy=%.3f\" %test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Prediction on New Data\n",
    "n=random.randint(0,9999)\n",
    "plt.imshow(x_test[n])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "test_predict=model.predict(x_test)\n",
    "test_predict_labels=np.argmax(test_predict,axis=1)\n",
    "confusion_matrix=tf.math.confusion_matrix(labels=y_test,predictions=test_predict_labels)\n",
    "print('confusion matrix of the test set :\\n', confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546c33b",
   "metadata": {},
   "source": [
    "With above code we can see that, throughout the epochs, our model accuracy increases and\n",
    "loss decreases that is good since our model gains confidence with our prediction\n",
    "This indicates the model is trained in a good way\n",
    "1. The two loss(loss and val_loss) are decreasing and the accuracy (accuracy and\n",
    "val_accuracy) increasing.\n",
    "2. The val_accuracy is the measure of how good the model is predicting so, it is observed\n",
    "that the model is well trained after 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3051e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
